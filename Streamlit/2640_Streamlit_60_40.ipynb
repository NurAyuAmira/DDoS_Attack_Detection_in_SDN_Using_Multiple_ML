{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNwPoBXCrfAD",
        "outputId": "6c3bd290-af0b-4a4f-f1bf-21db5d912e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKpkuyGb5GUT",
        "outputId": "831466b7-4ca0-4b7d-a5a3-21bf98108898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing Ddos_Attack_Detection2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Ddos_Attack_Detection2.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# Title of the Streamlit app\n",
        "st.title(\"Data Understanding and Exploration\")\n",
        "\n",
        "# Upload CSV file\n",
        "uploaded_file = st.file_uploader(\"Upload CSV file\", type=[\"csv\"])\n",
        "if uploaded_file is not None:\n",
        "    # Read the data from the CSV file in chunks to handle large files\n",
        "    chunk_size = 10000\n",
        "    df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
        "\n",
        "    # Initial Data Exploration\n",
        "    st.header(\"Initial Data Exploration\")\n",
        "    st.write(\"Shape of the DataFrame:\")\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Adjust display settings\n",
        "    pd.set_option('display.max_columns', 100)\n",
        "    pd.set_option('display.max_rows', 100)\n",
        "    pd.set_option('display.width', 1000)\n",
        "    pd.set_option('display.max_colwidth', 20)\n",
        "\n",
        "    st.header(\"Descriptive Statistics\")\n",
        "    st.write(df.describe())\n",
        "\n",
        "    # Frequency Counts for Categorical Variable\n",
        "    if ' Label' in df.columns:\n",
        "        st.header(\"Frequency Counts for 'Label'\")\n",
        "        frequency_counts = df[' Label'].value_counts()\n",
        "        st.write(frequency_counts)\n",
        "\n",
        "        label_counts = df[' Label'].value_counts()\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(label_counts)))\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        bars = plt.bar(label_counts.index, label_counts.values, color=colors, edgecolor='black')\n",
        "        plt.grid(True, which='major', linestyle='--', linewidth='0.5', color='grey')\n",
        "        plt.gca().set_axisbelow(True)\n",
        "\n",
        "        for i, val in enumerate(label_counts):\n",
        "            plt.text(i, val, str(val), ha='center', va='bottom')\n",
        "\n",
        "        plt.title('Bar Chart of Label')\n",
        "        plt.xlabel(' Label')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.legend(bars, label_counts.index, title=\"Types\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(plt.gcf())\n",
        "\n",
        "    # Data Preparation\n",
        "    st.header(\"Data Preparation\")\n",
        "\n",
        "    # Drop Irrelevant Features\n",
        "    st.subheader(\"Drop Irrelevant Features\")\n",
        "    initial_columns = df.columns.tolist()\n",
        "    irrelevant_features = ['Unnamed: 0', 'Flow ID', ' Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Timestamp', ' Protocol', 'SimillarHTTP', ' Inbound']\n",
        "    df = df.drop(irrelevant_features, axis=1)\n",
        "    dropped_features = [feature for feature in irrelevant_features if feature in initial_columns]\n",
        "    st.write(f\"Features dropped: {dropped_features}\")\n",
        "    st.write(\"DataFrame after dropping irrelevant features:\")\n",
        "    st.write(df.head())\n",
        "\n",
        "    additional_features_to_drop = [' Init_Win_bytes_backward', 'Init_Win_bytes_forward', ' Fwd Header Length.1', 'Fwd IAT Total']\n",
        "    df = df.drop(columns=additional_features_to_drop, errors='ignore')\n",
        "    dropped_additional_features = [feature for feature in additional_features_to_drop if feature in initial_columns]\n",
        "    st.write(f\"Additional features dropped: {dropped_additional_features}\")\n",
        "    st.write(\"DataFrame and Shape after dropping additional specified columns:\")\n",
        "    st.write(df.head())\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Drop Duplicate Rows\n",
        "    duplicate_rows = df.duplicated()\n",
        "    st.write(\"Number of duplicate rows: \", duplicate_rows.sum())\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    st.write(\"DataFrame and Shape after dropping duplicate rows:\")\n",
        "    st.write(df.head())\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Drop Missing Values (Rows)\n",
        "    missing_values = df.isnull().sum()\n",
        "    st.write(\"Missing values in each column before cleaning:\\n\", missing_values)\n",
        "    df = df.dropna()\n",
        "    missing_values_cleaned = df.isnull().sum()\n",
        "    st.write(\"Missing values in each column after cleaning:\\n\", missing_values_cleaned)\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Identify and Replace Infinite Values\n",
        "    inf_values = df.select_dtypes(include=[np.number]).applymap(np.isinf)\n",
        "    inf_counts = inf_values.sum()\n",
        "    st.write(\"Infinite values in each column:\\n\", inf_counts)\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "    st.write(\"Infinite values after replacing infinite values and dropping NaNs:\")\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Drop Columns with More Than 50% Zero Values\n",
        "    zero_val_percent = (df == 0).astype(int).sum(axis=0) / df.shape[0] * 100\n",
        "    threshold = 50\n",
        "    columns_to_drop = zero_val_percent[zero_val_percent > threshold].index\n",
        "    st.write(f\"Columns identified for dropping (greater than {threshold}% zeros):\")\n",
        "    st.write(columns_to_drop)\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "    st.write(df.shape)\n",
        "\n",
        "    # Drop Columns with More Than 50% Negative Values\n",
        "    negative_columns = [col for col in df.select_dtypes(include=['int64', 'float64']).columns if (df[col] < 0).mean() > 0.5]\n",
        "    st.write(\"Columns with more than 50% negative values:\")\n",
        "    st.write(negative_columns)\n",
        "    df = df.drop(columns=negative_columns)\n",
        "    st.write(\"Shape after dropping columns with more than 50% negative values: \", df.shape)\n",
        "\n",
        "    # Drop Rows with Any Negative Value\n",
        "    numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
        "    negative_values = numerical_columns < 0\n",
        "    records_with_negative = df[negative_values.any(axis=1)]\n",
        "    st.write(\"Number of rows with negative values in numerical columns:\", len(records_with_negative))\n",
        "    columns_with_negative = numerical_columns.columns[(negative_values.any())]\n",
        "    st.write(\"Numerical columns with negative values:\")\n",
        "    st.write(columns_with_negative)\n",
        "    df = df[~negative_values.any(axis=1)]\n",
        "    st.write(\"Shape after dropping rows with negative values: \", df.shape)\n",
        "\n",
        "    # Frequency Counts for Categorical Variable\n",
        "    st.header(\"Frequency Counts for 'Label'\")\n",
        "    frequency_counts = df[' Label'].value_counts()\n",
        "    st.write(frequency_counts)\n",
        "\n",
        "    label_counts = df[' Label'].value_counts()\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(label_counts)))\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    bars = plt.bar(label_counts.index, label_counts.values, color=colors, edgecolor='black')\n",
        "    plt.grid(True, which='major', linestyle='--', linewidth='0.5', color='grey')\n",
        "    plt.gca().set_axisbelow(True)\n",
        "\n",
        "    for i, val in enumerate(label_counts):\n",
        "        plt.text(i, val, str(val), ha='center', va='bottom')\n",
        "\n",
        "    plt.title('Bar Chart of Label')\n",
        "    plt.xlabel(' Label')\n",
        "    plt.ylabel('Frequency ')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend(bars, label_counts.index, title=\"Types\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(plt.gcf())\n",
        "\n",
        "    # Data Transformation - Label Encoder\n",
        "    st.header(\"Data Transformation - Label Encoder\")\n",
        "    df[' Label'] = df[' Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
        "    st.write(\"Label distribution after transformation:\")\n",
        "    st.write(df[' Label'].value_counts())\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
        "    plt.title('Distribution of Labels')\n",
        "    plt.xlabel(' Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1], ['Benign (0)', 'DDoS (1)'])\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    # Data Standardization\n",
        "    st.header(\"Data Standardization\")\n",
        "    X = df.drop(' Label', axis=1)\n",
        "    y = df[' Label']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "    df_scaled[' Label'] = y.values\n",
        "\n",
        "    st.write(\"Standardized DataFrame\")\n",
        "    st.write(df_scaled.head())\n",
        "\n",
        "    # Data Balancing\n",
        "    st.header(\"Data Balancing\")\n",
        "    df_majority = df_scaled[df_scaled[' Label'] == 0]\n",
        "    df_minority = df_scaled[df_scaled[' Label'] == 1]\n",
        "\n",
        "    desired_sample_size = 7000\n",
        "\n",
        "    df_majority_undersampled = df_majority.sample(n=desired_sample_size, random_state=42)\n",
        "    df_minority_undersampled = df_minority.sample(n=desired_sample_size, random_state=42)\n",
        "\n",
        "    df_balanced = pd.concat([df_majority_undersampled, df_minority_undersampled])\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
        "    plt.title('Distribution of Labels (Balanced)')\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha='center', va='baseline', fontsize=12, color='black', xytext=(0, 5),\n",
        "                    textcoords='offset points')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1], ['Benign (0)', 'DDoS (1)'])\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df_balanced.to_csv('Cleaned_Dataset.csv', index=False)\n",
        "    st.write(\"File saved as 'Cleaned_Dataset.csv'\")\n",
        "\n",
        "    # Load and Read Dataset (CIC-DDoS2019 - Day 2)\n",
        "    st.header(\"Load and Read Dataset (CIC-DDoS2019 - Day 2)\")\n",
        "    df_cleaned = pd.read_csv('Cleaned_Dataset.csv')\n",
        "    st.write(\"First few rows of the cleaned dataset:\")\n",
        "    st.write(df_cleaned.head())\n",
        "\n",
        "\n",
        "# Data Splitting (70:30)\n",
        "    st.header(\"Data Splitting (60:40)\")\n",
        "    X = df_cleaned.drop(' Label', axis=1)\n",
        "    y = df_cleaned[' Label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "    st.write(\"Training set (X):\", X_train.shape)\n",
        "    st.write(\"Training set (y):\", y_train.shape)\n",
        "    st.write(\"Test set (X):\", X_test.shape)\n",
        "    st.write(\"Test set (y):\", y_test.shape)\n",
        "\n",
        "    # Plot the distribution of the target in the training and testing sets\n",
        "    plt.figure(figsize=(14, 7))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    train_counts = y_train.value_counts()\n",
        "    train_bar = train_counts.plot(kind='bar', title='Distribution of target in training set', color='skyblue')\n",
        "    plt.xticks(rotation=0)\n",
        "    for i, value in enumerate(train_counts):\n",
        "        plt.text(i, value + value * 0.01, f'{value}', ha='center', va='bottom')\n",
        "        plt.xticks([0, 1], ['Benign (0)', 'DDoS (1)'])\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    test_counts = y_test.value_counts()\n",
        "    test_bar = test_counts.plot(kind='bar', title='Distribution of target in testing set', color='salmon')\n",
        "    plt.xticks(rotation=0)\n",
        "    for i, value in enumerate(test_counts):\n",
        "        plt.text(i, value + value * 0.01, f'{value}', ha='center', va='bottom')\n",
        "        plt.xticks([0, 1], ['Benign (0)', 'DDoS (1)'])\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.3)\n",
        "    plt.suptitle('Target Distribution in Training and Testing Sets in CIC-DDoS2019')\n",
        "    train_bar.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    test_bar.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.subplot(1, 2, 1).set_facecolor('whitesmoke')\n",
        "    plt.subplot(1, 2, 2).set_facecolor('whitesmoke')\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    # Feature Selection PCA (60:40)\n",
        "    st.header(\"Feature Selection PCA (60:40)\")\n",
        "    pca = PCA(n_components=25)\n",
        "    pca.fit(X_train)\n",
        "    X_train_pca = pca.transform(X_train)\n",
        "    X_test_pca = pca.transform(X_test)\n",
        "    st.write(\"Training set after PCA (X):\", X_train_pca.shape)\n",
        "    st.write(\"Test set after PCA (X):\", X_test_pca.shape)\n",
        "\n",
        "    feature_names = X_train.columns.tolist()\n",
        "    pca_components = pd.DataFrame(pca.components_, columns=feature_names)\n",
        "\n",
        "    pc1_contributions = pca_components.iloc[0]\n",
        "    pc2_contributions = pca_components.iloc[1]\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.bar(feature_names, pc1_contributions, alpha=0.5, label='PC1')\n",
        "    plt.bar(feature_names, pc2_contributions, alpha=0.5, label='PC2', bottom=pc1_contributions)\n",
        "    plt.title('Feature Contributions to the First Two Principal Components')\n",
        "    plt.xlabel('Feature Names')\n",
        "    plt.ylabel('Contribution')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.legend()\n",
        "    st.pyplot(plt)\n",
        "\n",
        "    # Feature Selection LDA (60:40)\n",
        "    st.header(\"Feature Selection LDA (60:40)\")\n",
        "    lda = LDA(n_components=1)\n",
        "    lda.fit(X_train, y_train)\n",
        "    X_train_lda = lda.transform(X_train)\n",
        "    X_test_lda = lda.transform(X_test)\n",
        "    st.write(\"Training set after LDA (X):\", X_train_lda.shape)\n",
        "    st.write(\"Test set after LDA (X):\", X_test_lda.shape)\n",
        "\n",
        "    lda_coefficients = lda.coef_[0]\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(feature_names, lda_coefficients)\n",
        "    plt.xlabel('Feature Names')\n",
        "    plt.ylabel('LDA Coefficient')\n",
        "    plt.title('LDA Coefficients for Each Feature')\n",
        "    plt.xticks(rotation=90)\n",
        "    st.pyplot(plt)\n",
        "\n",
        "\n",
        "    #### Default Parameter [kernel = linear] - TRAIN - WITHOUT FS\n",
        "\n",
        "    # Initialize an SVM with a linear kernel\n",
        "    svm_train_linear_wf = SVC(kernel=\"linear\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_linear_wf = svm_train_linear_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_linear_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_linear_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: Linear) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel = linear] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_linear_wf = svm_train_linear_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_linear_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_linear_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-Linear) -Train and Test Set - Without Feature Selection. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10]}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel Linear without Feature Selection : {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel: linear, C=10] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a linear kernel\n",
        "    svm_train_linear_wf = SVC(kernel=\"linear\", C=10)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_linear_wf = svm_train_linear_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_linear_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_linear_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Linear, C=10) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel: linear, C=10] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_linear_wf = svm_train_linear_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_linear_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_linear_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Linear, C=10) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    #### Default Parameter [kernel = linear] - TRAIN - WITH PCA\n",
        "\n",
        "    # Initialize an SVM with a linear kernel\n",
        "    svm_train_linear_f = SVC(kernel=\"linear\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_linear_f = svm_train_linear_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_linear_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_linear_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: Linear) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel = linear] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_linear_f = svm_train_linear_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_linear_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_linear_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-Linear) -Train and Test Set - Without Feature Selection. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10]}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel Linear with PCA : {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel: linear, C=10] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a linear kernel\n",
        "    svm_train_linear_f = SVC(kernel=\"linear\", C=10)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_linear_f = svm_train_linear_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_linear_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_linear_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Linear, C=10) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel: linear, C=10] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_linear_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_linear_f = svm_train_linear_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_linear_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_linear_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Linear, C=10) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ## Implementation : Support Vector Machine KERNEL: POLYNOMIAL\n",
        "\n",
        "    ### Implementation of SVM (Kernel- Polynomial) Train and Test Set - Without Feature Selection - DEFAULT\n",
        "\n",
        "    #### Default Parameter [kernel=\"poly\"] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a poly kernel\n",
        "    svm_train_poly_wf = SVC(kernel=\"poly\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_poly_wf = svm_train_poly_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_poly_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_poly_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: Polynomial) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel=\"poly\"] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_poly_wf = svm_train_poly_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_poly_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_poly_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-Poly) -Train and Test Set - Without Feature Selection. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10], 'degree': [2, 3]}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel Polynomial without Feature Selection: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel: poly, C=10, degree=3] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a poly kernel\n",
        "    svm_train_poly_wf = SVC(kernel=\"poly\", C=10, degree=3)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_poly_wf = svm_train_poly_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_poly_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_poly_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Polynomial, C=10, Degree=3) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel: poly, C=10, degree=3] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_poly_wf = svm_train_poly_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_poly_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_poly_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Polynomial, C=10, Degree=3) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-Polynomial) -Train and Test Set - With PCA. - DEFAULT\n",
        "\n",
        "    #### Default Parameter [kernel=\"poly\"] - TRAIN\n",
        "\n",
        "    # Train the SVM classifier with a polynomial kernel on the selected features\n",
        "    svm_train_poly_f = SVC(kernel=\"poly\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_poly_f = svm_train_poly_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_poly_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_poly_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: Polynomial) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel=\"poly\"] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_poly_f = svm_train_poly_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_poly_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_poly_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-Poly) -Train and Test Set - With PCA - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10], 'degree': [2, 3]}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel Polynomial with PCA: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel: poly, C=10, degree=3] - TRAIN\n",
        "\n",
        "    # Train the SVM classifier with a polynomial kernel on the selected features\n",
        "    svm_train_poly_f = SVC(kernel=\"poly\", degree=3, C=10)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_poly_f = svm_train_poly_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_poly_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_poly_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Polynomial, C=10, Degree=3) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel: poly, C=10, degree=3] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_poly_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_poly_f = svm_train_poly_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_poly_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_poly_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: Polynomial, C=10, Degree=3) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ## Implementation : Support Vector Machine KERNEL: RBF\n",
        "\n",
        "    ### Implementation of SVM (Kernel - RBF) - Train and Test Set - Without Feature Selection - DEFAULT\n",
        "\n",
        "    #### Default Parameter [kernel = rbf] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a rbf kernel\n",
        "    svm_train_rbf_wf = SVC(kernel=\"rbf\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_rbf_wf = svm_train_rbf_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_rbf_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_rbf_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: RBF) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel = rbf] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_rbf_wf = svm_train_rbf_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_rbf_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_rbf_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel RBF) - Train and Test Set - Without Feature Selection - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10], 'gamma': ['scale', 'auto']}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel RBF without Feature Selection: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel: rbf, C=10, gamma=scale] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a rbf kernel\n",
        "    svm_train_rbf_wf = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_rbf_wf = svm_train_rbf_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_rbf_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_rbf_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: RBF, C=10, Gamma=scale) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel: rbf, C=10, gamma=scale] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_rbf_wf = svm_train_rbf_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_rbf_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_rbf_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: RBF, C=10, Gamma=scale) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-RBF) using PCA - Train and Test set - DEFAULT\n",
        "\n",
        "    #### Default Parameter [kernel=rbf] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a rbf kernel\n",
        "    svm_train_rbf_f = SVC(kernel=\"rbf\")\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_rbf_f = svm_train_rbf_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_rbf_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_rbf_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"SVM (Kernel: RBF) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [kernel=rbf] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_rbf_f = svm_train_rbf_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_rbf_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_rbf_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of SVM (Kernel-RBF) using PCA - Train and Test set - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {'C': [1, 10], 'gamma': ['scale', 'auto']}\n",
        "\n",
        "    # Initialize the SVM model\n",
        "    svm = SVC()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(svm, param_grid, cv=5, factor=2, n_jobs=-1)\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters for Kernel RBF using PCA: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [kernel=rbf, C=10, gamma=auto] - TRAIN\n",
        "\n",
        "    # Initialize an SVM with a rbf kernel\n",
        "    svm_train_rbf_f = SVC(kernel=\"rbf\", C=10, gamma='auto')\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_rbf_f = svm_train_rbf_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_rbf_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_rbf_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: RBF, C=10, Gamma=auto) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [kernel=rbf, C=10, gamma=auto] - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    svm_train_rbf_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_rbf_f = svm_train_rbf_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_rbf_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_rbf_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Kernel: RBF, C=10, Gamma=auto) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # KNN (70:30)\n",
        "\n",
        "    ## Implementation for KNN (Euclidean)\n",
        "\n",
        "    ### Implementation of KNN (Euclidean) -- Train and Test Set  Without Feature Selection.- DEFAULT\n",
        "\n",
        "    #### Default Parameter [metric=Euclidean] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_train_euclidean_wf = KNeighborsClassifier(n_neighbors=91, metric='euclidean', p=2) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_euclidean_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_euclidean_wf = knn_train_euclidean_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_euclidean_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_euclidean_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Euclidean) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric=Euclidean] -TEST\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_test_euclidean_wf = KNeighborsClassifier(n_neighbors=91,metric='euclidean', p=2)\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_euclidean_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_euclidean_wf = knn_test_euclidean_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_euclidean_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_euclidean_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of KNN (Euclidean) -- Train and Test Set  Without Feature Selection.- HALVING GRID SEARCH\n",
        "\n",
        "    from sklearn.experimental import enable_halving_search_cv\n",
        "    from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['euclidean']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    ####  Tuning Parameter [metric=Euclidean,'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_train_euclidean_wf = KNeighborsClassifier(n_neighbors=87, metric='euclidean', p=2)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_euclidean_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_euclidean_wf = knn_train_euclidean_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_euclidean_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_euclidean_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Euclidean, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [metric=Euclidean'n_neighbors': 87] -TEST\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_test_euclidean_wf = KNeighborsClassifier(n_neighbors=87,metric='euclidean', p=2)\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_euclidean_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_euclidean_wf = knn_test_euclidean_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_euclidean_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_euclidean_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Euclidean, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of KNN (Metric-euclidean) -Train Set and Test Set - With PCA. - DEFAULT\n",
        "\n",
        "    #### Default Parameter [metric=Euclidean] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_train_euclidean_f = KNeighborsClassifier(n_neighbors=91,metric='euclidean', p=2) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_euclidean_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_euclidean_f = knn_train_euclidean_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_euclidean_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_euclidean_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Euclidean) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric=Euclidean] -TEST\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_test_euclidean_f = KNeighborsClassifier(n_neighbors=91,metric='euclidean', p=2) #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_euclidean_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_euclidean_f = knn_test_euclidean_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_euclidean_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_euclidean_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of KNN (Euclidean) -- Train and Test Set  With PCA.- HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['euclidean']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    ####  Tuning Parameter [metric=Euclidean,'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_train_euclidean_f = KNeighborsClassifier(n_neighbors=87,metric='euclidean', p=2) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_euclidean_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_euclidean_f = knn_train_euclidean_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_euclidean_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_euclidean_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Euclidean, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [metric=Euclidean'n_neighbors': 95] -TEST\n",
        "\n",
        "    # Initialize an knn with a euclidean Metric\n",
        "    knn_test_euclidean_f = KNeighborsClassifier(n_neighbors=87,metric='euclidean', p=2) #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_euclidean_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_euclidean_f = knn_test_euclidean_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_euclidean_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_euclidean_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Euclidean, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "\n",
        "    ## Implementation for KNN (Manhattan)\n",
        "\n",
        "    ### Implementation of KNN (Manhattan) -- Train and Test Set  Without Feature Selection.- DEFAULT\n",
        "\n",
        "    #### Default Parameter [metric-Manhattan] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_train_manhattan_wf = KNeighborsClassifier(n_neighbors=91, metric='manhattan', p=1) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_manhattan_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_manhattan_wf = knn_train_manhattan_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_manhattan_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_manhattan_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Manhattan) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric=Manhattan] -TEST\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_test_manhattan_wf = KNeighborsClassifier(n_neighbors=91, metric='manhattan', p=1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_manhattan_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_manhattan_wf = knn_test_manhattan_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_manhattan_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_manhattan_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of KNN (Manhattan) -- Train and Test Set  Without Feature Selection.- HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['manhattan']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    ####  Tuning Parameter [metric=Manhattan,'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_train_manhattan_wf = KNeighborsClassifier(n_neighbors=87, metric='manhattan', p=1)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_manhattan_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_manhattan_wf = knn_train_manhattan_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_manhattan_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_manhattan_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Manhattan, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ####  Tuning Parameter [metric=Manhattan,'n_neighbors': 87] -TEST\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_test_manhattan_wf = KNeighborsClassifier(n_neighbors=87, metric='manhattan', p=1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_manhattan_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_manhattan_wf = knn_test_manhattan_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_manhattan_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_manhattan_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Manhattan, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of knn (Metric-manhattan) -Train Set and Test Set - With PCA. - DEFAULT\n",
        "\n",
        "    #### Default Parameter [metric-Manhattan] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_train_manhattan_f = KNeighborsClassifier(n_neighbors=91, metric='manhattan', p=1) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_manhattan_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_manhattan_f = knn_train_manhattan_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_manhattan_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_manhattan_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Manhattan) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric-Manhattan] -TEST\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_test_manhattan_f = KNeighborsClassifier(n_neighbors=91, metric='manhattan', p=1) #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_manhattan_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_manhattan_f = knn_test_manhattan_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_manhattan_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_manhattan_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of KNN (Manhattan) -- Train and Test Set  With PCA.- HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['manhattan']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    ####  Tuning Parameter [metric=Manhattan,'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_train_manhattan_f = KNeighborsClassifier(n_neighbors=87, metric='manhattan', p=1) #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_manhattan_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_manhattan_f = knn_train_manhattan_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_manhattan_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_manhattan_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Manhattan, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ####  Tuning Parameter [metric=Manhattan,'n_neighbors': 87] -TEST\n",
        "\n",
        "    # Initialize an knn with a manhattan Metric\n",
        "    knn_test_manhattan_f = KNeighborsClassifier(n_neighbors=87, metric='manhattan', p=1) #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_manhattan_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_manhattan_f = knn_test_manhattan_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_manhattan_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_manhattan_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Manhattan, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ## Implementation for KNN (Cosine)\n",
        "\n",
        "    ### Implementation of KNN (cosine) -Train Set & Test Set - Without Feature Selection. - Default\n",
        "\n",
        "    #### Default Parameter [metric=Cosine] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_train_cosine_wf = KNeighborsClassifier(n_neighbors=91, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_cosine_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_cosine_wf = knn_train_cosine_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_cosine_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_cosine_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Cosine) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric=Cosine] -TEST\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_test_cosine_wf = KNeighborsClassifier(n_neighbors=91, metric='cosine')\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_cosine_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_cosine_wf = knn_test_cosine_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_cosine_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_cosine_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of KNN (cosine) -Train Set & Test Set - Without Feature Selection. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['cosine']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [metric=Cosine, 'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_train_cosine_wf = KNeighborsClassifier(n_neighbors=87, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_cosine_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_cosine_wf = knn_train_cosine_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_cosine_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_cosine_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Cosine, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [metric=Cosine,'n_neighbors': 87] -TEST\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_test_cosine_wf = KNeighborsClassifier(n_neighbors=87, metric='cosine')\n",
        "\n",
        "    start_time = time.time()\n",
        "    knn_test_cosine_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "   # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_cosine_wf = knn_test_cosine_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_cosine_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_cosine_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Cosine, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    ### Implementation of KNN (cosine) -Train Set & Test Set -With PCA - Default\n",
        "\n",
        "    #### Default Parameter [metric=Cosine] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_train_cosine_f = KNeighborsClassifier(n_neighbors=99, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_cosine_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_cosine_f = knn_train_cosine_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_cosine_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_cosine_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"KNN (Cosine) - With PCA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter [metric=Cosine] -TEST\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_test_cosine_f = KNeighborsClassifier(n_neighbors=99, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_cosine_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_cosine_f = knn_test_cosine_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_cosine_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_cosine_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of KNN (cosine) -Train Set & Test Set - With PCA. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_neighbors': [87,89],\n",
        "        'metric': ['cosine']\n",
        "    }\n",
        "\n",
        "    # Initialize the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(knn, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter [metric=Cosine, 'n_neighbors': 87] -TRAIN\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_train_cosine_f = KNeighborsClassifier(n_neighbors=87, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    knn_train_cosine_f.fit(X_train_pca, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_cosine_f = knn_train_cosine_f.predict(X_train_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_cosine_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_cosine_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Cosine, n_neighbors=87) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter [metric=Cosine,'n_neighbors': 87] -TEST\n",
        "\n",
        "    # Initialize an knn with a cosine Metric\n",
        "    knn_test_cosine_f = KNeighborsClassifier(n_neighbors=87, metric='cosine') #sqrt\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    knn_test_cosine_f.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_cosine_f = knn_test_cosine_f.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_cosine_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_cosine_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Cosine, n_neighbors=87) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ## Implementation : Naive Bayes - Classification: GaussianBayes\n",
        "\n",
        "    ### Implementation of NB (Gb) -Train Set and Test Set - Without Feature Selection. - DEFAULT\n",
        "\n",
        "    #### Default Parameter GNB - TRAIN\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_train_gb_wf = GaussianNB()\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_gb_wf = nb_train_gb_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_gb_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_gb_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"Naive Bayes (Gaussian) - Without Feature Selection - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter GNB - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_gb_wf = nb_train_gb_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_gb_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_gb_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "\n",
        "    ### Implementation of NB (Gb) -Train Set and Test Set - Without Feature Selection. - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'var_smoothing': np.logspace(-9, 0, 10)\n",
        "    }\n",
        "\n",
        "    # Initialize the GaussianNB model\n",
        "    gnb = GaussianNB()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(gnb, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter GNB - TRAIN\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_train_gb_wf = GaussianNB(var_smoothing=0.01)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_wf.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_gb_wf = nb_train_gb_wf.predict(X_train)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_gb_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_gb_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Gaussian, var_smoothing=0.01) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter GNB - TEST\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_test_gb_wf = GaussianNB(var_smoothing=0.01)\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    nb_test_gb_wf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_gb_wf = nb_test_gb_wf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_gb_wf)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_gb_wf)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Gaussian, var_smoothing=0.01) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of nb (Kernel-gb) -Train Set and Test Set- With LDA - DEFAULT\n",
        "\n",
        "    #### Default Parameter GNB - TRAIN\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_train_gb_f = GaussianNB()\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_f.fit(X_train_lda, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_gb_f = nb_train_gb_f.predict(X_train_lda)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_gb_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_gb_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"Naive Bayes (Gaussian) - With LDA - Default Parameters\")\n",
        "    st.subheader(\"Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Default Parameter GNB - TEST\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_f.fit(X_test_lda, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_gb_f = nb_train_gb_f.predict(X_test_lda)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_gb_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_gb_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "    ### Implementation of nb (Kernel-gb) -Train Set and Test Set- With LDA - HALVING GRID SEARCH\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'var_smoothing': np.logspace(-9, 0, 10)\n",
        "    }\n",
        "\n",
        "    # Initialize the GaussianNB model\n",
        "    gnb = GaussianNB()\n",
        "\n",
        "    # Initialize HalvingGridSearchCV for faster results\n",
        "    halving_grid_search = HalvingGridSearchCV(gnb, param_grid, cv=5, factor=2,  n_jobs=-1)\n",
        "\n",
        "    halving_grid_search.fit(X_train_lda, y_train)\n",
        "\n",
        "    best_params = halving_grid_search.best_params_\n",
        "    st.subheader(\"Best Hyperparameters Tuning\")\n",
        "    st.write(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "    #### Tuning Parameter GNB - TRAIN\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_train_gb_f = GaussianNB(var_smoothing=1e-05)\n",
        "\n",
        "    # Measure training time\n",
        "    start_time = time.time()\n",
        "    nb_train_gb_f.fit(X_train_lda, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_train_pred_gb_f = nb_train_gb_f.predict(X_train_lda)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_gb_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_train, y_train_pred_gb_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Gaussian, var_smoothing=1e-05) - Training Results\")\n",
        "    st.write(f\"Training time: {training_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "    #### Tuning Parameter GNB - TEST\n",
        "\n",
        "    # Initialize an nb with a gb kernel\n",
        "    nb_test_gb_f = GaussianNB(var_smoothing=1e-05)\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    nb_test_gb_f.fit(X_test_lda, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred_gb_f = nb_test_gb_f.predict(X_test_lda)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_gb_f)\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_test, y_test_pred_gb_f)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.subheader(\"Tuned Parameters (Gaussian, var_smoothing=1e-05) - Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(class_report)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize the models with better hyperparameters\n",
        "    svm_rbf_clf = SVC(probability=True, kernel='rbf', C=10, gamma='auto')\n",
        "    knn_man_clf = KNeighborsClassifier(metric='manhattan', n_neighbors=87, weights='distance', algorithm='auto')\n",
        "    nb_clf = GaussianNB(var_smoothing=1e-05)\n",
        "\n",
        "    # Create an ensemble using VotingClassifier with unique names\n",
        "    ensemble_clf = VotingClassifier(estimators=[\n",
        "        ('svm_rbf', svm_rbf_clf),\n",
        "        ('knn_manhattan', knn_man_clf),\n",
        "        ('naive_bayes', nb_clf)\n",
        "    ], voting='soft', n_jobs=-1)  # Use all available cores\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    ensemble_clf.fit(X_test, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred = ensemble_clf.predict(X_test)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy on test data\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"Ensemble Model - Without Feature Selection\")\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(report)\n",
        "\n",
        "    ## Ensemble - SVM, KNN, NB - With PCA\n",
        "\n",
        "    # Initialize the models with better hyperparameters\n",
        "    svm_rbf_clf = SVC(probability=True, kernel='rbf', C=10, gamma='auto')\n",
        "    knn_man_clf = KNeighborsClassifier(metric='manhattan', n_neighbors=87, weights='distance', algorithm='auto')\n",
        "    nb_clf = GaussianNB(var_smoothing=1e-05)\n",
        "\n",
        "\n",
        "    # Create an ensemble using VotingClassifier with unique names\n",
        "    ensemble_clf = VotingClassifier(estimators=[\n",
        "        ('svm_rbf', svm_rbf_clf),\n",
        "        ('knn_manhattan', knn_man_clf),\n",
        "        ('naive_bayes', nb_clf)\n",
        "    ], voting='soft', n_jobs=-1)  # Use all available cores\n",
        "\n",
        "    # Measure testing time\n",
        "    start_time = time.time()\n",
        "    ensemble_clf.fit(X_test_pca, y_test)\n",
        "    testing_time = time.time() - start_time\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "    y_test_pred = ensemble_clf.predict(X_test_pca)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Calculate accuracy on test data\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "    # Display the results in Streamlit\n",
        "    st.header(\"Ensemble Model - With PCA\")\n",
        "    st.subheader(\"Testing Results\")\n",
        "    st.write(f\"Testing time: {testing_time:.4f} seconds\")\n",
        "    st.write(f\"Prediction time: {prediction_time:.4f} seconds\")\n",
        "    st.write(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.text(report)\n",
        "\n",
        "    # Define the summary results for all models\n",
        "    data = {\n",
        "        'Model': [\n",
        "            'SVM (Linear) - Default', 'SVM (Linear) - Tuned',\n",
        "            'SVM (Linear + PCA) - Default', 'SVM (Linear + PCA) - Tuned',\n",
        "            'SVM (Poly) - Default', 'SVM (Poly) - Tuned',\n",
        "            'SVM (Poly + PCA) - Default', 'SVM (Poly + PCA) - Tuned',\n",
        "            'SVM (RBF) - Default', 'SVM (RBF) - Tuned',\n",
        "            'SVM (RBF + PCA) - Default', 'SVM (RBF + PCA) - Tuned',\n",
        "            'KNN (Euclidean) - Default', 'KNN (Euclidean) - Tuned',\n",
        "            'KNN (Euclidean + PCA) - Default', 'KNN (Euclidean + PCA) - Tuned',\n",
        "            'KNN (Manhattan) - Default', 'KNN (Manhattan) - Tuned',\n",
        "            'KNN (Manhattan + PCA) - Default', 'KNN (Manhattan + PCA) - Tuned',\n",
        "            'KNN (Cosine) - Default', 'KNN (Cosine) - Tuned',\n",
        "            'KNN (Cosine + PCA) - Default', 'KNN (Cosine + PCA) - Tuned',\n",
        "            'NB (Gaussian) - Default', 'NB (Gaussian) - Tuned',\n",
        "            'NB (Gaussian + LDA) - Default', 'NB (Gaussian + LDA) - Tuned',\n",
        "            'Ensemble - Without Feature Selection', 'Ensemble - With PCA'\n",
        "        ],\n",
        "        'Training Accuracy': [\n",
        "            0.8455, 0.8658, 0.8458, 0.8675, 0.8206, 0.8757, 0.8207, 0.8840, 0.9054, 0.9513, 0.9055, 0.9579,\n",
        "            0.9405, 0.9455, 0.9405, 0.9455, 0.9510, 0.9563, 0.9446, 0.9467, 0.9383, 0.9442, 0.9368, 0.9440,\n",
        "            0.7887, 0.7876, 0.8093, 0.8093, 0.9614, 0.9811\n",
        "        ],\n",
        "        'Testing Accuracy': [\n",
        "            0.8775, 0.8864, 0.8764, 0.8814, 0.8014, 0.8652, 0.8000, 0.8661, 0.9005, 0.9427, 0.9007, 0.9596,\n",
        "            0.9330, 0.9313, 0.9330, 0.9313, 0.9402, 0.9389, 0.9339, 0.9339, 0.9257, 0.9268, 0.9257, 0.9270,\n",
        "            0.7836, 0.7837, 0.8018, 0.8018, 0.9614, 0.9811\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Create the DataFrame\n",
        "    summary_df = pd.DataFrame(data)\n",
        "\n",
        "    # Display the summary table in Streamlit\n",
        "    st.header(\"Summary of Model Results (60:40 Split Ratios)\")\n",
        "    st.dataframe(summary_df)\n",
        "\n",
        "\n",
        "    # Visualization\n",
        "    st.header(\"Visualization of Model Performance\")\n",
        "\n",
        "    ## Average Performance of Different Models\n",
        "    svm_avg_accuracy = 0.8768\n",
        "    knn_avg_accuracy = 0.9315\n",
        "    nb_avg_accuracy = 0.7948\n",
        "    ensemble_avg_accuracy = 0.9709\n",
        "\n",
        "    labels = ['SVM', 'KNN', 'NB', 'Ensemble']\n",
        "    avg_accuracies = [svm_avg_accuracy, knn_avg_accuracy, nb_avg_accuracy, ensemble_avg_accuracy]\n",
        "    colors = ['blue', 'green', 'red', 'purple']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(labels, avg_accuracies, color=colors, alpha=0.7)\n",
        "    ax.set_xlabel('Model', fontsize=8)\n",
        "    ax.set_ylabel('Average Test Accuracy', fontsize=8)\n",
        "    ax.set_title('Average Performance of Different Models', fontsize=8)\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 4), ha='center', va='bottom',fontsize=8)\n",
        "\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    ## Average Performance Across All Combinations\n",
        "    accuracy_values = {\n",
        "        'Linear SVM': [0.874, 0.8733, 0.8775, 0.8764, 0.8886, 0.8864, 0.8864, 0.8814],\n",
        "        'Polynomial SVM': [0.7988, 0.7986, 0.8014, 0.8, 0.8529, 0.8629, 0.8652, 0.8661],\n",
        "        'RBF SVM': [0.8881, 0.8881, 0.9005, 0.9007, 0.926, 0.9467, 0.9427, 0.9596],\n",
        "        'KNN Euclidean': [0.9348, 0.9355, 0.935, 0.9357, 0.933, 0.933, 0.9313, 0.9313],\n",
        "        'KNN Manhattan': [0.9417, 0.9321, 0.9412, 0.9333, 0.9402, 0.9339, 0.9389, 0.9339],\n",
        "        'KNN Cosine': [0.9207, 0.9212, 0.9257, 0.9261, 0.9221, 0.9221, 0.9268, 0.927],\n",
        "        'Naive Bayes': [0.7886, 0.8019, 0.7836, 0.8018, 0.795, 0.8019, 0.7837, 0.8018],\n",
        "        'Ensemble': [0.9574, 0.9829, 0.9623, 0.9811]\n",
        "    }\n",
        "\n",
        "    average_accuracies = {model: np.mean(acc) for model, acc in accuracy_values.items()}\n",
        "    sorted_accuracies = dict(sorted(average_accuracies.items(), key=lambda item: item[1]))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(13, 10))\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_accuracies)))\n",
        "    bars = ax.bar(sorted_accuracies.keys(), sorted_accuracies.values(), color=colors, edgecolor='black')\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.01, round(yval, 4), ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    ax.set_xlabel('Model', fontsize=12)\n",
        "    ax.set_ylabel('Average Test Accuracy', fontsize=12)\n",
        "    ax.set_title('Average Performance Across All Combinations', fontsize=16)\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    ax.axhline(y=0.5, color='r', linestyle='--', linewidth=1)\n",
        "\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    ## Impact of Different Kernels in SVM\n",
        "    data = {\n",
        "        'Kernel': ['Linear', 'Polynomial', 'RBF'],\n",
        "        'Default_70_30': [0.874, 0.7988, 0.8881],\n",
        "        'Tuned_70_30': [0.8886, 0.8529, 0.926],\n",
        "        'Default_60_40': [0.8775, 0.8014, 0.9005],\n",
        "        'Tuned_60_40': [0.8864, 0.8652, 0.9427],\n",
        "        'Default_70_30_FS': [0.8733, 0.7986, 0.8881],\n",
        "        'Tuned_70_30_FS': [0.8864, 0.8629, 0.9467],\n",
        "        'Default_60_40_FS': [0.8764, 0.8000, 0.9007],\n",
        "        'Tuned_60_40_FS': [0.8814, 0.8661, 0.9596]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['Average'] = df[['Default_70_30', 'Tuned_70_30', 'Default_60_40', 'Tuned_60_40',\n",
        "                        'Default_70_30_FS', 'Tuned_70_30_FS', 'Default_60_40_FS', 'Tuned_60_40_FS']].mean(axis=1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars = ax.bar(df['Kernel'], df['Average'], color=['red', 'blue', 'green'])\n",
        "    ax.set_xlabel('SVM Kernel')\n",
        "    ax.set_ylabel('Average Test Accuracy')\n",
        "    ax.set_title('Comparison of SVM Kernels (Average Test Accuracy)')\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.grid(axis='y')\n",
        "\n",
        "    for index, value in enumerate(df['Average']):\n",
        "        ax.text(index, value + 0.01, f'{value:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    ## Impact of Different Metrics in KNN\n",
        "    data = {\n",
        "        'Kernel': ['Euclidean', 'Manhattan', 'Cosine'],\n",
        "        'Default_70_30': [0.9348, 0.9417, 0.9207],\n",
        "        'Tuned_70_30': [0.9355, 0.9412, 0.9221],\n",
        "        'Default_60_40': [0.9330, 0.9402, 0.9257],\n",
        "        'Tuned_60_40': [0.9313, 0.9389, 0.9268],\n",
        "        'Default_70_30_FS': [0.9350, 0.9321, 0.9212],\n",
        "        'Tuned_70_30_FS': [0.9357, 0.9333, 0.9221],\n",
        "        'Default_60_40_FS': [0.9330, 0.9339, 0.9261],\n",
        "        'Tuned_60_40_FS': [0.9313, 0.9339, 0.9270]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['Average'] = df[['Default_70_30', 'Tuned_70_30', 'Default_60_40', 'Tuned_60_40',\n",
        "                        'Default_70_30_FS', 'Tuned_70_30_FS', 'Default_60_40_FS', 'Tuned_60_40_FS']].mean(axis=1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars = ax.bar(df['Kernel'], df['Average'], color=['red', 'blue', 'green'])\n",
        "    ax.set_xlabel('KNN Metrics')\n",
        "    ax.set_ylabel('Average Test Accuracy')\n",
        "    ax.set_title('Comparison of KNN Metrics (Average Test Accuracy)')\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.grid(axis='y')\n",
        "\n",
        "    for index, value in enumerate(df['Average']):\n",
        "        ax.text(index, value + 0.01, f'{value:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    ## Impact of Feature Selection on Model Performance\n",
        "    accuracy_70_30 = {\n",
        "        \"without_fs\": [0.874, 0.8886, 0.7988, 0.8529, 0.8881, 0.926, 0.9348, 0.9355, 0.9417, 0.9412, 0.9207, 0.9221, 0.7886, 0.795, 0.9574],\n",
        "        \"with_fs\": [0.8733, 0.8864, 0.7986, 0.8629, 0.8881, 0.9467, 0.935, 0.9357, 0.9321, 0.9333, 0.9212, 0.9221, 0.8019, 0.8019, 0.9829]\n",
        "    }\n",
        "\n",
        "    accuracy_60_40 = {\n",
        "        \"without_fs\": [0.8775, 0.8864, 0.8014, 0.8652, 0.9005, 0.9427, 0.933, 0.9313, 0.9402, 0.9389, 0.9257, 0.9268, 0.7836, 0.7837, 0.9623],\n",
        "        \"with_fs\": [0.8764, 0.8814, 0.8, 0.8661, 0.9007, 0.9596, 0.933, 0.9313, 0.9339, 0.9339, 0.9261, 0.927, 0.8018, 0.8018, 0.9811]\n",
        "    }\n",
        "\n",
        "    average_without_fs = np.mean(accuracy_70_30[\"without_fs\"] + accuracy_60_40[\"without_fs\"])\n",
        "    average_with_fs = np.mean(accuracy_70_30[\"with_fs\"] + accuracy_60_40[\"with_fs\"])\n",
        "\n",
        "    categories = ['Without Feature Selection', 'With Feature Selection']\n",
        "    averages = [average_without_fs, average_with_fs]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    bars = ax.bar(categories, averages, color=['blue', 'green'], width=0.8)\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    ax.set_xlabel('Feature Selection', fontsize=8)\n",
        "    ax.set_ylabel('Average Test Accuracy', fontsize=8)\n",
        "    ax.set_title('Comparison of Test Accuracy with and without Feature Selection', fontsize=8)\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    ## Default vs Tuned Models\n",
        "    data = {\n",
        "        'Model': ['SVM_Linear', 'SVM_Polynomial', 'SVM_RBF', 'KNN_Euclidean', 'KNN_Manhattan', 'KNN_Cosine', 'NB_Gaussian'],\n",
        "        'Default_70_30': [0.874, 0.7988, 0.8881, 0.9348, 0.9417, 0.9207, 0.7886],\n",
        "        'Default_60_40': [0.8775, 0.8014, 0.9005, 0.933, 0.9402, 0.9257, 0.7836],\n",
        "        'Tuned_70_30': [0.8886, 0.8529, 0.926, 0.9355, 0.9412, 0.9221, 0.795],\n",
        "        'Tuned_60_40': [0.8864, 0.8652, 0.9427, 0.9313, 0.9389, 0.9268, 0.7837],\n",
        "        'Default_FS_70_30': [0.8733, 0.7986, 0.8881, 0.935, 0.9321, 0.9212, 0.8019],\n",
        "        'Default_FS_60_40': [0.8764, 0.8, 0.9007, 0.933, 0.9339, 0.9261, 0.8018],\n",
        "        'Tuned_FS_70_30': [0.8884, 0.8629, 0.9467, 0.9357, 0.9333, 0.9221, 0.8019],\n",
        "        'Tuned_FS_60_40': [0.8814, 0.8661, 0.9596, 0.9313, 0.9339, 0.927, 0.8018]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['Default_Avg'] = df[['Default_70_30', 'Default_60_40']].mean(axis=1)\n",
        "    df['Tuned_Avg'] = df[['Tuned_70_30', 'Tuned_60_40']].mean(axis=1)\n",
        "    df['Default_FS_Avg'] = df[['Default_FS_70_30', 'Default_FS_60_40']].mean(axis=1)\n",
        "    df['Tuned_FS_Avg'] = df[['Tuned_FS_70_30', 'Tuned_FS_60_40']].mean(axis=1)\n",
        "\n",
        "    default_avg = df['Default_Avg'].mean()\n",
        "    tuned_avg = df['Tuned_Avg'].mean()\n",
        "    default_fs_avg = df['Default_FS_Avg'].mean()\n",
        "    tuned_fs_avg = df['Tuned_FS_Avg'].mean()\n",
        "\n",
        "    labels_without_fs = ['Default', 'Tuned']\n",
        "    averages_without_fs = [default_avg, tuned_avg]\n",
        "    colors_without_fs = ['#1f77b4', '#ff7f0e']\n",
        "\n",
        "    x_without_fs = np.arange(len(labels_without_fs))\n",
        "    width = 0.4\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "    rects1 = ax1.bar(x_without_fs, averages_without_fs, width, label='Accuracy', color=colors_without_fs, edgecolor='black')\n",
        "\n",
        "    ax1.set_ylabel('Average Accuracy', fontsize=14)\n",
        "    ax1.set_title('Average Accuracy by Default and Tuned Models without Feature Selection', fontsize=16)\n",
        "    ax1.set_xticks(x_without_fs)\n",
        "    ax1.set_xticklabels(labels_without_fs, fontsize=12)\n",
        "    ax1.grid(True, axis='y', linestyle='--', linewidth=0.7)\n",
        "\n",
        "    for rect in rects1:\n",
        "        height = rect.get_height()\n",
        "        ax1.annotate('{}'.format(round(height, 4)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 5),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    labels_with_fs = ['Default_FS', 'Tuned_FS']\n",
        "    averages_with_fs = [default_fs_avg, tuned_fs_avg]\n",
        "    colors_with_fs = ['#2ca02c', '#d62728']\n",
        "\n",
        "    x_with_fs = np.arange(len(labels_with_fs))\n",
        "    width = 0.4\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "    rects2 = ax2.bar(x_with_fs, averages_with_fs, width, label='Accuracy', color=colors_with_fs, edgecolor='black')\n",
        "\n",
        "    ax2.set_ylabel('Average Accuracy', fontsize=14)\n",
        "    ax2.set_title('Average Accuracy by Default and Tuned Models with Feature Selection', fontsize=16)\n",
        "    ax2.set_xticks(x_with_fs)\n",
        "    ax2.set_xticklabels(labels_with_fs, fontsize=12)\n",
        "    ax2.grid(True, axis='y', linestyle='--', linewidth=0.7)\n",
        "\n",
        "    for rect in rects2:\n",
        "        height = rect.get_height()\n",
        "        ax2.annotate('{}'.format(round(height, 4)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 5),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    fig2.tight_layout()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    ## Performance Across Different Splitting Ratios\n",
        "    data_split = {\n",
        "        'Model': ['SVM_Linear', 'SVM_Polynomial', 'SVM_RBF', 'KNN_Euclidean', 'KNN_Manhattan', 'KNN_Cosine', 'NB_Gaussian'],\n",
        "        'Default_70_30': [0.874, 0.7988, 0.8881, 0.9348, 0.9417, 0.9207, 0.7886],\n",
        "        'Default_60_40': [0.8775, 0.8014, 0.9005, 0.933, 0.9402, 0.9257, 0.7836],\n",
        "        'Tuned_70_30': [0.8886, 0.8529, 0.926, 0.9355, 0.9412, 0.9221, 0.795],\n",
        "        'Tuned_60_40': [0.8864, 0.8652, 0.9427, 0.9313, 0.9389, 0.9268, 0.7837],\n",
        "        'Default_FS_70_30': [0.8733, 0.7986, 0.8881, 0.935, 0.9321, 0.9212, 0.8019],\n",
        "        'Default_FS_60_40': [0.8764, 0.8, 0.9007, 0.933, 0.9339, 0.9261, 0.8018],\n",
        "        'Tuned_FS_70_30': [0.8884, 0.8629, 0.9467, 0.9357, 0.9333, 0.9221, 0.8019],\n",
        "        'Tuned_FS_60_40': [0.8814, 0.8661, 0.9596, 0.9313, 0.9339, 0.927, 0.8018]\n",
        "    }\n",
        "\n",
        "    df_split = pd.DataFrame(data_split)\n",
        "    df_split['Avg_70_30'] = df_split[['Default_70_30', 'Tuned_70_30']].mean(axis=1)\n",
        "    df_split['Avg_60_40'] = df_split[['Default_60_40', 'Tuned_60_40']].mean(axis=1)\n",
        "    df_split['Avg_FS_70_30'] = df_split[['Default_FS_70_30', 'Tuned_FS_70_30']].mean(axis=1)\n",
        "    df_split['Avg_FS_60_40'] = df_split[['Default_FS_60_40', 'Tuned_FS_60_40']].mean(axis=1)\n",
        "\n",
        "    avg_70_30 = df_split['Avg_70_30'].mean()\n",
        "    avg_60_40 = df_split['Avg_60_40'].mean()\n",
        "    avg_fs_70_30 = df_split['Avg_FS_70_30'].mean()\n",
        "    avg_fs_60_40 = df_split['Avg_FS_60_40'].mean()\n",
        "\n",
        "    labels_without_fs = ['70/30 Split', '60/40 Split']\n",
        "    averages_without_fs = [avg_70_30, avg_60_40]\n",
        "    colors_without_fs = ['#1f77b4', '#ff7f0e']\n",
        "\n",
        "    x_without_fs = np.arange(len(labels_without_fs))\n",
        "    width = 0.4\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "    rects1 = ax1.bar(x_without_fs, averages_without_fs, width, label='Accuracy', color=colors_without_fs, edgecolor='black')\n",
        "\n",
        "    ax1.set_ylabel('Average Accuracy', fontsize=14)\n",
        "    ax1.set_title('Average Accuracy by Splitting Ratio without Feature Selection', fontsize=16)\n",
        "    ax1.set_xticks(x_without_fs)\n",
        "    ax1.set_xticklabels(labels_without_fs, fontsize=12)\n",
        "    ax1.grid(True, axis='y', linestyle='--', linewidth=0.7)\n",
        "\n",
        "    for rect in rects1:\n",
        "        height = rect.get_height()\n",
        "        ax1.annotate('{}'.format(round(height, 4)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 5),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    fig1.tight_layout()\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    labels_with_fs = ['70/30 Split (FS)', '60/40 Split (FS)']\n",
        "    averages_with_fs = [avg_fs_70_30, avg_fs_60_40]\n",
        "    colors_with_fs = ['#2ca02c', '#d62728']\n",
        "\n",
        "    x_with_fs = np.arange(len(labels_with_fs))\n",
        "    width = 0.4\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "    rects2 = ax2.bar(x_with_fs, averages_with_fs, width, label='Accuracy', color=colors_with_fs, edgecolor='black')\n",
        "\n",
        "    ax2.set_ylabel('Average Accuracy', fontsize=14)\n",
        "    ax2.set_title('Average Accuracy by Splitting Ratio with Feature Selection', fontsize=16)\n",
        "    ax2.set_xticks(x_with_fs)\n",
        "    ax2.set_xticklabels(labels_with_fs, fontsize=12)\n",
        "    ax2.grid(True, axis='y', linestyle='--', linewidth=0.7)\n",
        "\n",
        "    for rect in rects2:\n",
        "        height = rect.get_height()\n",
        "        ax2.annotate('{}'.format(round(height, 4)),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 5),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    fig2.tight_layout()\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "\n",
        "else:\n",
        "      st.write(\"Please upload a CSV file to begin.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgkuEyL6rio7",
        "outputId": "e464c358-a071-4329-ec15-0e8869d6cddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.83.13.119:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.291s\n",
            "your url is: https://early-poems-smile.loca.lt\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:28: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.concat([chunk for chunk in pd.read_csv(uploaded_file, chunksize=chunk_size)])\n",
            "/content/Ddos_Attack_Detection2.py:173: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df, palette='coolwarm')\n",
            "/content/Ddos_Attack_Detection2.py:210: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x=' Label', data=df_balanced, palette='pastel')\n"
          ]
        }
      ],
      "source": [
        "!streamlit run Ddos_Attack_Detection2.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}